{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06495ebd",
   "metadata": {},
   "source": [
    "# ðŸš€ Step 1: Initialize Class Environment (Click Run) ðŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eccdc12",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# --- TEACHER CONFIGURATION ---\n",
    "# Paste your Hugging Face token between the quotes below.\n",
    "part_1 = \"hf\"\n",
    "part_2 = \"_NohyiEXNSIjeCkeyPD\"\n",
    "part_3 = \"LHCIilWruzzseeLU\"\n",
    "# NEVER SHARE YOUR TOKEN UNDER NORMAL CONDITIONS. NOT MY REAL PERSONAL TOKEN. - Evan.\n",
    "CLASS_TOKEN = part_1 + part_2 + part_3\n",
    "# -----------------------------\n",
    "\n",
    "# 1. Download the Project\n",
    "if not os.path.exists('Simplified-How-LLMs-Work-Visualized'):\n",
    "    print(\"ðŸ“‚ Downloading Class Resources... ðŸ“‚\")\n",
    "    !git clone https://github.com/evanfarnping/Simplified-How-LLMs-Work-Visualized.git\n",
    "else:\n",
    "    print(\"ðŸ“‚ Resources already downloaded. ðŸ“‚\")\n",
    "\n",
    "# 2. Install Dependencies\n",
    "print(\"â³â³â³ Installing AI Engines (This may take a few minutes)... â³â³â³\")\n",
    "%cd Simplified-How-LLMs-Work-Visualized\n",
    "\n",
    "# If pip something seems broken, disable '> /dev/null 2>&1'\n",
    "!pip install -q -r requirements.txt > /dev/null 2>&1\n",
    "\n",
    "# 3. Log in to Hugging Face\n",
    "from huggingface_hub import login\n",
    "print(\"ðŸ”‘ Authenticating... ðŸ”‘\")\n",
    "try:\n",
    "    if CLASS_TOKEN.startswith(\"hf_\"):\n",
    "        login(token=CLASS_TOKEN, add_to_git_credential=True)\n",
    "        print(\"âœ…âœ…âœ… Success! You are logged in and ready. âœ…âœ…âœ…\")\n",
    "    else:\n",
    "        print(\"âš ï¸âš ï¸âš ï¸ WARNING: Teacher Token is missing or invalid. âš ï¸âš ï¸âš ï¸\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒâŒâŒ Login Failed: {e} âŒâŒâŒ\")\n",
    "\n",
    "# 4. Helper to show results\n",
    "from IPython.display import Image, Video, display, clear_output\n",
    "import glob\n",
    "\n",
    "def show_latest_results():\n",
    "    print(\"\\n--- EXPERIMENT RESULTS ---\")\n",
    "    \n",
    "    videos = glob.glob(\"export/*.mp4\")\n",
    "    if videos:\n",
    "        latest_video = max(videos, key=os.path.getctime)\n",
    "        print(f\"ðŸŽ¬ Showing Video: {latest_video}\")\n",
    "        display(Video(latest_video, embed=True, width=600))\n",
    "    \n",
    "    images = glob.glob(\"export/*.png\")\n",
    "    if images:\n",
    "        # Sort by time to show mostly recent ones\n",
    "        latest_images = sorted(images, key=os.path.getctime, reverse=True)[:2]\n",
    "        for img in latest_images:\n",
    "            print(f\"Showing Chart: {img}\")\n",
    "            display(Image(filename=img))\n",
    "\n",
    "    if not videos and not images:\n",
    "        print(\"âš ï¸âš ï¸âš ï¸ No results found yet. Run an experiment first! âš ï¸âš ï¸âš ï¸\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bd350f",
   "metadata": {},
   "source": [
    "# ðŸ§ª Step 2: Run a Pre-Made Scenario ðŸ§ª\n",
    "## Select an experiment from the list and click Run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22770042",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "Scenario = \"medical_bias\" # @param [\"medical_bias\", \"safety_overrides\", \"server_prompting\",\"bad_prompts_vs._good_prompts\", \"knowledge_cutoff\", \"simple_vs._complex_models\", \"thinking_vs._chat_models\", \"bias_in_roles\", \"fake_empathy_vs._logic\", \"chinese_vs._USA_data\",\"LLMs_suck\", \"negative_vs._positive_AIs\", \"raw_LLMS_vs._chatbot_LLMs\",\"spelling_and_structure_matter!\"]\n",
    "\n",
    "# Construct the path\n",
    "script_path = f\"scenarios_to_try/{Scenario}/scenario.py\"\n",
    "\n",
    "print(f\"âš¡ Running Experiment: {Scenario} âš¡\")\n",
    "print(\"Please wait while the model loads...\")\n",
    "\n",
    "# Run & Display\n",
    "!python \"{script_path}\"\n",
    "show_latest_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f8ba83",
   "metadata": {},
   "source": [
    "# ðŸŽ›ï¸ Step 3: Custom Lab Bench (More Advanced) ðŸŽ›ï¸ \n",
    "## Tweak settings and run your own unique experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f25852",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"main_configs\"))\n",
    "sys.path.append(os.path.abspath(\"src\"))\n",
    "import main as engine\n",
    "\n",
    "# --- MODEL CONTROLS --- #\n",
    "Model = \"Phi-4-mini-4B\" # @param [\"GPT-2\", \"Pythia-160M\", \"Qwen2.5-0.5B\", \"TinyLlama-1.1B\", \"Qwen3-1.7B\", \"Phi-4-mini-4B\", \"Mistral-7B\", \"Qwen2.5-14B\", \"DeepSeek-Lite\", \"Qwen2.5-32B\", \"DeepSeek-R1\", \"Jamba-2-Mini\",\"Qwen2.5-72B\", \"Llama-4-Scout\"]\n",
    "\n",
    "Persona = \"direct\" # @param [\"default\", \"direct\", \"caveman\", \"one-word\", \"angry\", \"nice\", \"liar\", \"biased\", \"pleaser\", \"insane\", \"sad\"]\n",
    "\n",
    "Prompt = \"Explain why the sky is blue.\" # @param {type:\"string\"}\n",
    "\n",
    "# Apply Settings #\n",
    "engine.SELECTED_MODEL = Model\n",
    "engine.CURRENT_PERSONA = Persona\n",
    "\n",
    "engine.RUN_PREDICTION_CHART = True # @param {type:\"boolean\"}\n",
    "engine.RUN_COMPARISON_VIDEO = False # @param {type:\"boolean\"}\n",
    "engine.RUN_SEQUENCE_CHART = False # @param {type:\"boolean\"}\n",
    "engine.RUN_SCAN_VIDEO = False # @param {type:\"boolean\"}\n",
    "engine.RUN_SENTIMENT_COMPASS = False # @param {type:\"boolean\"}\n",
    "\n",
    "engine.PRED_CHART_PROMPT = Prompt\n",
    "engine.PRED_CHART_TOP_K = 5\n",
    "engine.PRED_CHART_FILENAME = Path(\"export/my_custom_chart.png\")\n",
    "\n",
    "print(f\"ðŸ§  Loading {Model} with Persona: {Persona}.. ðŸ§ .\")\n",
    "try:\n",
    "    engine.main()\n",
    "    show_latest_results()\n",
    "except Exception as e:\n",
    "    print(f\"âŒâŒâŒ Error: {e} âŒâŒâŒ\")\n",
    "    print(\"If you ran out of memory, go to 'Runtime' -> 'Restart Session' and try again.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
