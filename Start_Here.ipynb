{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06495ebd",
   "metadata": {},
   "source": [
    "# ðŸš€ Step 1: Initialize Class Environment (Click Run) ðŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eccdc12",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# --- TEACHER CONFIGURATION ---\n",
    "# Split paste your Hugging Face token between the quotes below.\n",
    "# You can get a token at https://huggingface.co/settings/tokens \n",
    "part_1 = \"hf\"\n",
    "part_2 = \"_NohyiEXNSIjeCkeyPD\"\n",
    "part_3 = \"LHCIilWruzzseeLU\"\n",
    "# NEVER SHARE YOUR TOKEN UNDER NORMAL CONDITIONS. NOT MY REAL PERSONAL TOKEN. - Evan.\n",
    "CLASS_TOKEN = part_1 + part_2 + part_3\n",
    "# -----------------------------\n",
    "\n",
    "# 1. Download\n",
    "if not os.path.exists('Simplified-How-LLMs-Work-Visualized'):\n",
    "    print(\"ðŸ“‚ Downloading Class Resources... ðŸ“‚\")\n",
    "    !git clone https://github.com/evanfarnping/Simplified-How-LLMs-Work-Visualized.git > /dev/null 2>&1\n",
    "else:\n",
    "    print(\"ðŸ“‚ Resources already downloaded. ðŸ“‚\")\n",
    "\n",
    "# Install\n",
    "print(\"â³ Installing AI Engines (Will take a few moments)... â³\")\n",
    "%cd Simplified-How-LLMs-Work-Visualized\n",
    "!pip install -q -r requirements.txt > /dev/null 2>&1 # Pip errors are blocked here.\n",
    "\n",
    "print(\"ðŸ”§ Configuring Environment... ðŸ”§\")\n",
    "video_script = \"src/make_comparison_video.py\"\n",
    "with open(video_script, \"r\") as f:\n",
    "    code = f.read()\n",
    "code = code.replace(\"figsize=(18, fig_height)\", \"figsize=(14, fig_height)\")\n",
    "code = code.replace(\"dpi=120\", \"dpi=100\")\n",
    "with open(video_script, \"w\") as f:\n",
    "    f.write(code)\n",
    "\n",
    "# Ensure Imports exist in Main\n",
    "main_script = \"main_configs/main.py\"\n",
    "with open(main_script, \"r\") as f:\n",
    "    main_code = f.read()\n",
    "if \"import threading\" not in main_code:\n",
    "    main_code = \"import threading\\n\" + main_code\n",
    "with open(main_script, \"w\") as f:\n",
    "    f.write(main_code)\n",
    "\n",
    "# Login\n",
    "from huggingface_hub import login\n",
    "print(\"ðŸ”‘ Authenticating... ðŸ”‘\")\n",
    "CLASS_TOKEN = part_1 + part_2 + part_3\n",
    "try:\n",
    "    if len(CLASS_TOKEN) > 7:\n",
    "        login(token=CLASS_TOKEN, add_to_git_credential=True)\n",
    "        print(\"âœ… Success! You are logged in and ready. âœ…\")\n",
    "    else:\n",
    "        print(\"âš ï¸ Token is empty. Gated models (Llama/Mistral) may fail. âš ï¸\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bd350f",
   "metadata": {},
   "source": [
    "# ðŸ§ª Step 2: Run a Pre-Made Scenario ðŸ§ª\n",
    "### Select an experiment from the list and click Run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22770042",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "from IPython.display import Image, Video, display\n",
    "\n",
    "Scenario = \"medical_bias\" # @param [\"medical_bias\", \"safety_overrides\", \"server_prompting\", \"bad_prompts_vs._good_prompts\", \"knowledge_cutoff\", \"simple_vs._complex_models\", \"thinking_vs._chat_models\", \"bias_in_roles\", \"fake_empathy_vs._logic\", \"chinese_vs._USA_data\",\"LLMs_suck\", \"negative_vs._positive_AIs\", \"raw_LLMS_vs._chatbot_LLMs\",\"spelling_and_structure_matter!\"]\n",
    "\n",
    "start_time = time.time()\n",
    "script_path = f\"scenarios_to_try/{Scenario}/scenario.py\"\n",
    "\n",
    "# Run\n",
    "print(f\"âš¡ Running Experiment: {Scenario} âš¡\")\n",
    "print(\"Please wait while the model loads for a few moments...\")\n",
    "!python \"{script_path}\"\n",
    "\n",
    "print(\"\\n--- RESULTS ---\")\n",
    "search_path = f\"scenarios_to_try/{Scenario}/*.mp4\"\n",
    "videos = glob.glob(search_path)\n",
    "images = glob.glob(f\"scenarios_to_try/{Scenario}/*.png\")\n",
    "\n",
    "new_videos = [v for v in videos if os.path.getmtime(v) > start_time]\n",
    "new_images = [i for i in images if os.path.getmtime(i) > start_time]\n",
    "if new_videos:\n",
    "    for vid in new_videos:\n",
    "        print(f\"Video Found: {os.path.basename(vid)}\")\n",
    "        display(Video(vid, embed=True, width=700))\n",
    "elif new_images:\n",
    "    for img in new_images:\n",
    "        print(f\"Image Found: {os.path.basename(img)}\")\n",
    "        display(Image(filename=img))\n",
    "else:\n",
    "    print(\"No new results found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f8ba83",
   "metadata": {},
   "source": [
    "# ðŸŽ›ï¸ Step 3: Custom Lab Bench (More Advanced) ðŸŽ›ï¸ \n",
    "### Tweak settings and run your own unique experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f25852",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import time\n",
    "from IPython.display import Image, Video, display\n",
    "\n",
    "sys.path.append(os.path.abspath(\"main_configs\"))\n",
    "sys.path.append(os.path.abspath(\"src\"))\n",
    "import main as engine\n",
    "\n",
    "# --- MODEL CONTROLS --- #\n",
    "Model = \"Phi-4-mini-4B\" # @param [\"GPT-2\", \"Pythia-160M\", \"Qwen2.5-0.5B\", \"TinyLlama-1.1B\", \"Qwen3-1.7B\", \"Phi-4-mini-4B\", \"Mistral-7B\", \"Qwen2.5-14B\", \"DeepSeek-Lite\", \"Qwen2.5-32B\", \"DeepSeek-R1\", \"Jamba-2-Mini\",\"Qwen2.5-72B\", \"Llama-4-Scout\"]\n",
    "\n",
    "Persona = \"direct\" # @param [\"default\", \"direct\", \"caveman\", \"one-word\", \"angry\", \"nice\", \"liar\", \"biased\", \"pleaser\", \"insane\", \"sad\"]\n",
    "\n",
    "Prompt = \"Explain why the sky is blue.\" # @param {type:\"string\"}\n",
    "\n",
    "# Apply Settings #\n",
    "engine.SELECTED_MODEL = Model\n",
    "engine.CURRENT_PERSONA = Persona\n",
    "\n",
    "engine.RUN_PREDICTION_CHART = True # @param {type:\"boolean\"}\n",
    "engine.RUN_COMPARISON_VIDEO = False # @param {type:\"boolean\"}\n",
    "engine.RUN_SEQUENCE_CHART = False # @param {type:\"boolean\"}\n",
    "engine.RUN_SCAN_VIDEO = False # @param {type:\"boolean\"}\n",
    "engine.RUN_SENTIMENT_COMPASS = False # @param {type:\"boolean\"}\n",
    "\n",
    "engine.PRED_CHART_PROMPT = Prompt\n",
    "engine.PRED_CHART_FILENAME = Path(\"my_prediction.png\")\n",
    "\n",
    "print(f\"ðŸ§  Loading {Model} with Persona: {Persona}.. ðŸ§ .\")\n",
    "try:\n",
    "    start_time = time.time()\n",
    "    engine.main()\n",
    "    \n",
    "    print(\"\\n--- RESULTS ---\")\n",
    "    \n",
    "    files_root = glob.glob(\"*.png\") + glob.glob(\"*.mp4\")\n",
    "    files_export = glob.glob(\"export/*.png\") + glob.glob(\"export/*.mp4\")\n",
    "    all_files = files_root + files_export\n",
    "    \n",
    "    new_files = [f for f in all_files if os.path.getmtime(f) > start_time]\n",
    "    if new_files:\n",
    "        # Sort so videos appear before images\n",
    "        new_files.sort(key=lambda x: x.endswith(\".png\"))\n",
    "        \n",
    "        for f in new_files:\n",
    "            print(f\"Displaying: {f}\")\n",
    "            if f.endswith(\".mp4\"):\n",
    "                display(Video(f, embed=True, width=700))\n",
    "            else:\n",
    "                display(Image(filename=f))\n",
    "            \n",
    "    if not new_files:\n",
    "        print(\"No output generated. (Check if you enabled a 'RUN' option above)\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Try restarting the runtime if you run out of memory.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
